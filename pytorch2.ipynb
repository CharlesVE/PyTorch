{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We need both a train and test dataset.\n",
    "These can be thought of as in and out-of-sample datasets.\n",
    "torchvision is for vision task related datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train = True, download = True, \n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train = False, download = True, \n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = True)\n",
    "testset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([1, 1, 5, 1, 1, 6, 1, 7, 6, 6])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of batches in our trainset...\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "x,y = data[0][0],data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " #plt.imshow(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above we can see that the shape of the data contains an additional dimension with value 1. For this reason we cannot simply plt and show our data, since matplotlib is expecting just the [28,28] part, not [1,28,28].\n",
    "\n",
    "Using '.view' we can solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x229c06626c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][0].view([28,28]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It is essential that our data is balanced. \n",
    "The reason for this is that, if we take an extreme example where we only give data for the written number 2, when we minimize our loss function it will optimise only for the number 2. By contrast, should we take a rouhgly even balance of all numbers from i in range(10) then when it optimises it shall do so for all numbers not just a select few, or in our example just one.\n",
    "\n",
    "Onwards to balancing the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total =0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)]+=1\n",
    "        total+=1\n",
    "\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:9.871666666666666\n",
      "1:11.236666666666666\n",
      "2:9.93\n",
      "3:10.218333333333334\n",
      "4:9.736666666666666\n",
      "5:9.035\n",
      "6:9.863333333333333\n",
      "7:10.441666666666666\n",
      "8:9.751666666666667\n",
      "9:9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}:{counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
