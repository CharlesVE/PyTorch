{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3391, -2.3129, -2.2768, -2.4165, -2.1883, -2.2132, -2.3056, -2.2178,\n",
       "         -2.3483, -2.4391]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---- Optimization ----\n",
    "\n",
    "Our optimizer is called Adam. Why? Adaptive Momentum. There are many types of optimizers (adagrad, adadelta etc.) but we're going with adaptive momentum because Adam has momentum updates for every parameter. Adam uses the expected values for past gradients. This means we are slow initially, but pick up speed over time, hence the term momentum. Adam can take different sized steps for different parameters, this is due to having momentum for every parameter. Having momentum for every parameter leads to faster convergence.\n",
    "\n",
    "This is our optimisation process...\n",
    "\n",
    "1 - read in the batch\n",
    "2 - zero the gradient\n",
    "3 - Run the batch through\n",
    "4 - Calculate the loss value and use backpropagation to optimise the parameters\n",
    "Repeat\n",
    "\n",
    "Step 2 might not be so intuitive. Once we've compared the output to the desired output we can calculate our gradients for each parameter from that. The gradients are essentially just information for updating weights. \n",
    "We must zero our gradient for every step to prevent re-optimizing for steps we've already optimized for. In theory you could re-set your gradient less often but that is neither helpful nor necessary in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0275, 0.2588, 0.7490, 1.0000, 0.9922, 0.9922, 0.7961,\n",
      "          0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.4706, 0.7333, 0.9882, 0.9882, 0.9922, 0.9882, 0.9882, 0.9882,\n",
      "          0.9059, 0.1255, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3490,\n",
      "          0.9922, 0.9882, 0.9882, 0.8392, 0.6588, 0.6588, 0.7686, 0.9882,\n",
      "          0.9922, 0.8941, 0.9176, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4431,\n",
      "          0.9922, 0.9882, 0.8392, 0.1098, 0.0000, 0.0000, 0.0392, 0.6980,\n",
      "          0.9922, 0.9882, 0.9882, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.9490, 0.9922, 0.9922, 0.7961, 0.0510, 0.0000, 0.0000, 0.0510,\n",
      "          0.9961, 0.9922, 0.9922, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.4549, 0.9882, 0.9882, 0.9882, 0.8118, 0.3686, 0.0510, 0.5412,\n",
      "          0.9922, 0.9882, 0.9137, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0275, 0.5843, 0.9882, 0.9882, 0.9922, 0.9882, 0.8196, 0.9647,\n",
      "          0.9922, 0.9882, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0275, 0.3059, 0.6980, 0.9922, 0.9882, 0.9882, 0.9882,\n",
      "          0.9922, 0.8902, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3098, 0.9922, 0.9922, 0.9922,\n",
      "          0.9961, 0.6000, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1137, 0.9882, 0.9882, 0.9882,\n",
      "          0.9922, 0.9882, 0.3176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.2588, 0.9882, 0.9882, 0.9882,\n",
      "          0.9922, 0.9882, 0.9176, 0.2314, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.2000, 0.9451, 0.9882, 0.8392, 0.1569,\n",
      "          0.4039, 0.9882, 0.9882, 0.5451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.9922, 0.2196, 0.0000,\n",
      "          0.1020, 0.9569, 0.9922, 0.7961, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.8824, 0.9922, 0.8392, 0.0745, 0.0000,\n",
      "          0.0000, 0.5647, 0.9882, 0.9882, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2627, 0.9647, 0.9569, 0.3176, 0.0000, 0.0000,\n",
      "          0.0000, 0.3725, 0.9882, 0.9882, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.3333, 0.9882, 0.9333, 0.1490, 0.0000, 0.0000,\n",
      "          0.1020, 0.9529, 0.9882, 0.9882, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2980, 0.9804, 0.9961, 0.6980, 0.2078, 0.3098,\n",
      "          0.8000, 0.9922, 0.9922, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.7843, 0.9922, 0.9882, 0.9882, 0.9882,\n",
      "          0.9922, 0.9882, 0.6667, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0980, 0.5020, 0.9882, 0.9882, 0.9882,\n",
      "          0.9922, 0.6667, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.4039, 0.7451, 0.3529,\n",
      "          0.1098, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "tensor(8)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.7216, 0.7882, 0.4824,\n",
      "          0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.3098,\n",
      "          0.5451, 0.0588, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4549, 0.8941, 0.9922, 0.9922, 0.9922,\n",
      "          0.1647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5804, 0.9922,\n",
      "          0.9922, 0.8275, 0.1255, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0078, 0.3647, 0.9137, 0.9961, 0.7922, 0.3569, 0.9098,\n",
      "          0.1490, 0.0000, 0.0000, 0.0000, 0.0588, 0.6039, 0.9647, 0.6157,\n",
      "          0.1490, 0.7725, 0.1490, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3647, 0.9922, 0.9922, 0.6078, 0.0824, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1608, 0.8863, 0.9922, 0.7804, 0.0824,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1412, 0.8784, 0.9922, 0.8196, 0.0706, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1412, 0.8784, 0.9922, 0.8196, 0.0706, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314,\n",
      "          0.6196, 0.9961, 0.8510, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0314, 0.6196, 1.0000, 0.9569, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3098,\n",
      "          0.9922, 0.9922, 0.4353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3098, 0.9922, 0.9647, 0.3255, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5804,\n",
      "          0.9922, 0.9176, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2471, 0.7922, 0.9922, 0.6667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5804,\n",
      "          0.9922, 0.9098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667,\n",
      "          0.8706, 0.9961, 0.7725, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5804,\n",
      "          0.9922, 0.9098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.7333,\n",
      "          0.9922, 0.9294, 0.2118, 0.0000, 0.0000, 0.1765, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5843,\n",
      "          0.9961, 0.9294, 0.0588, 0.0000, 0.0000, 0.0000, 0.1569, 0.9961,\n",
      "          0.9961, 0.3490, 0.0000, 0.1922, 0.8588, 0.3412, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2706,\n",
      "          0.9922, 0.9922, 0.7255, 0.0549, 0.0000, 0.0000, 0.8118, 0.9922,\n",
      "          0.8549, 0.1961, 0.6471, 0.9725, 0.6667, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157,\n",
      "          0.5294, 0.9882, 0.9922, 0.9294, 0.8471, 0.6392, 0.9882, 0.9922,\n",
      "          0.9608, 0.9647, 0.9922, 0.6745, 0.0275, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5294, 0.9922, 0.9922, 0.9961, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.8510, 0.6039, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0157, 0.1647, 0.5098, 0.8235, 0.9922, 0.9608, 0.4784,\n",
      "          0.1647, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.8275, 0.9961, 0.6000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.3176, 0.9961, 0.8824, 0.0549, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4196, 0.9961, 0.6588, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1412, 0.9961, 0.6588, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.4078, 0.5569, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "tensor(4)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549,\n",
      "          0.4078, 0.7294, 0.9961, 0.9961, 1.0000, 0.8157, 0.2784, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.4353, 0.6039, 0.8784,\n",
      "          0.9922, 0.9922, 0.9922, 0.9294, 0.7882, 0.9922, 0.6824, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1725, 0.8980, 0.9412, 0.6824, 0.3765,\n",
      "          0.9333, 0.8941, 0.3333, 0.0706, 0.2314, 0.9922, 0.6824, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0392, 0.8353, 0.6157, 0.2392, 0.0000, 0.1059,\n",
      "          0.4275, 0.0510, 0.0000, 0.0000, 0.2902, 0.9922, 0.6824, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.8196, 0.7843, 0.0706, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1490, 0.3765, 0.7569, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0902, 0.6745, 0.2314, 0.0706, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.9216, 0.8471, 0.4706, 0.4784, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0588, 0.9647, 0.9922, 0.6510, 0.0078, 0.0000, 0.0000,\n",
      "          0.0000, 0.0275, 0.9216, 0.9608, 0.5922, 0.0824, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2784, 0.9451, 0.9922, 0.3412, 0.0000, 0.0745,\n",
      "          0.3373, 0.7804, 0.9922, 0.3451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5765, 0.9922, 0.8902, 0.2431, 0.6431,\n",
      "          0.9922, 0.8824, 0.2784, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0196, 0.7569, 0.9922, 0.9922, 0.9059,\n",
      "          0.4353, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.3765, 0.8784, 0.9961, 0.9961, 0.3882,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0314, 0.6980, 0.9686, 0.9373, 0.9569, 0.8431, 0.0902,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1098, 0.8039, 0.9961, 0.8471, 0.2118, 0.4196, 0.9922, 0.3843,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686,\n",
      "          0.7529, 0.9922, 0.6039, 0.0980, 0.0000, 0.0353, 0.8157, 0.4431,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6000,\n",
      "          0.9922, 0.8431, 0.0000, 0.0000, 0.0000, 0.0941, 0.9020, 0.7647,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6902,\n",
      "          0.9961, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.7686, 0.6784,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5098,\n",
      "          0.9922, 0.4353, 0.0000, 0.0000, 0.0000, 0.0000, 0.7647, 0.4157,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941,\n",
      "          0.5569, 0.9922, 0.4588, 0.0471, 0.0000, 0.0000, 0.6471, 0.6471,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0706, 0.6000, 0.9333, 0.9294, 0.6510, 0.1608, 0.6196, 0.3255,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1412, 0.5804, 0.9922, 0.8980, 0.0902, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "# This code below is just used to print our first tensor set,\n",
    "# in order to have an illustration to refer back to...\n",
    "\n",
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data\n",
    "        print(X[0])\n",
    "        print(y[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0103, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "EPOCH = 3\n",
    "\n",
    "for epoch in range(EPOCH): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value (nll = negative log likelihood)\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0103, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are 2 primary ways to calculate loss.\n",
    "If the input targets are one hot vectors, e.g [0,0,0,1,0], then we use the mean squared error. Our metrics aren't one hot, they're a singular value. Therefore we're using nl loss. nl loss refers to negative log likelihood loss."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--- Accuracy ---\n",
    "\n",
    "As we iterate we get loss. But in order to test our accuracy we iterate over our test set. We measure correcteness by comparing our output values to our target values.\n",
    "\n",
    "We use torch.no_grad in order to not calculate gradients. This is because we just want to see how well the model we have built does in the out of sample period. We do not want to optimise on our out of sample data, only test the accuracy of our model!\n",
    "We use our testset because this is the out of sample part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.971\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        # idx = image number, i= output columns vector\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:,.â˜º ,\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we can see what the 0th element is in our dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The machine correctly predicted the 0th element as a 7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below we shall see an example just passing through the 0th value.\n",
    "First it is reshaped so that it can be taken in as a column vector instead of a 2x2 matrix.\n",
    "Then it is passed through net in order get the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.9216e+01, -1.3071e+01, -1.1887e+01, -9.3777e+00, -1.8265e+01,\n",
      "        -1.9229e+01, -3.4389e+01, -9.7628e-05, -1.3482e+01, -1.2836e+01],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "a_featureset = X[0]\n",
    "reshaped_for_network = a_featureset.view(-1,784) # 784 b/c 28*28 image resolution.\n",
    "output = net(reshaped_for_network) #output will be a list of network predictions.\n",
    "first_pred = output[0]\n",
    "print(first_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we use argmax to determine which of the number values (0,1,2,...9) the computer thinks it is most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "biggest_index = torch.argmax(first_pred)\n",
    "print(biggest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
